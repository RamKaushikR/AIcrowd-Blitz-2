{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "ROOT_DIR = os.path.abspath('/storage/Mask_RCNN')\n",
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn import utils, visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(utils.Dataset):\n",
    "    def load_dataset(self, dataset_dir, dtype, return_coco=True):\n",
    "        self.dtype = dtype\n",
    "        if self.dtype == 'train':\n",
    "            annotation_path = os.path.join(dataset_dir, 'train.json')\n",
    "            image_dir = os.path.join(dataset_dir, 'train_images')\n",
    "        elif self.dtype == 'val':\n",
    "            annotation_path = os.path.join(dataset_dir, 'val.json')\n",
    "            image_dir = os.path.join(dataset_dir, 'val_images')\n",
    "\n",
    "        print('Annotation Path ', annotation_path)\n",
    "        print('Image Dir ', image_dir)\n",
    "        assert os.path.exists(annotation_path) and os.path.exists(image_dir)\n",
    "\n",
    "        self.coco = COCO(annotation_path)\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        classIds = self.coco.getCatIds()\n",
    "        image_ids = list(self.coco.imgs.keys())\n",
    "\n",
    "        for _class_id in classIds:\n",
    "            self.add_class('mask-detection', _class_id, self.coco.loadCats(_class_id)[0]['name'])\n",
    "\n",
    "        for _img_id in image_ids:\n",
    "            assert(os.path.exists(os.path.join(image_dir, self.coco.imgs[_img_id]['file_name'])))\n",
    "            self.add_image(\n",
    "                'mask-detection', image_id=_img_id,\n",
    "                path=os.path.join(image_dir, self.coco.imgs[_img_id]['file_name']),\n",
    "                width=self.coco.imgs[_img_id]['width'],\n",
    "                height=self.coco.imgs[_img_id]['height'],\n",
    "                annotations=self.coco.loadAnns(self.coco.getAnnIds(imgIds=[_img_id], catIds=classIds, iscrowd=None)))\n",
    "\n",
    "        if return_coco:\n",
    "            return self.coco\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        assert image_info['source'] == 'mask-detection'\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        annotations = self.image_info[image_id]['annotations']\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            class_id = self.map_source_class_id(\n",
    "                'mask-detection.{}'.format(annotation['category_id']))\n",
    "            if class_id:\n",
    "                m = self.annToMask(annotation, image_info['height'], image_info['width'])\n",
    "                if m.max() < 1:\n",
    "                    continue\n",
    "\n",
    "                instance_masks.append(m)\n",
    "                class_ids.append(class_id)\n",
    "        \n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            return super(MaskDataset, self).load_mask(image_id)\n",
    "\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        return 'mask-detection::{}'.format(image_id)\n",
    "\n",
    "    def annToRLE(self, ann, height, width):\n",
    "        segm = ann['segmentation']\n",
    "        if isinstance(segm, list):\n",
    "            rles = maskUtils.frPyObjects(segm, height, width)\n",
    "            rle = maskUtils.merge(rles)\n",
    "        elif isinstance(segm['counts'], list):\n",
    "            rle = maskUtils.frPyObjects(segm, height, width)\n",
    "        else:\n",
    "            rle = ann['segmentation']\n",
    "        return rle\n",
    "\n",
    "    def annToMask(self, ann, height, width):\n",
    "        rle = self.annToRLE(ann, height, width)\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConfig(Config):\n",
    "    NAME = 'mask-detection'\n",
    "    IMAGES_PER_GPU = 2\n",
    "    GPU_COUNT = 1\n",
    "    BACKBONE = 'resnet50'\n",
    "    NUM_CLASSES = 3  # 1 Background + 2 classes(mask/no_mask)\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "    MEAN_PIXEL = np.array([0., 0., 0.])\n",
    "\n",
    "    STEPS_PER_EPOCH = 340\n",
    "    VALIDATION_STEPS = 60\n",
    "    MAX_GT_INSTANCES = 35\n",
    "    LEARNING_RATE = 0.001\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    MINI_MASK_SHAPE = (128, 128)\n",
    "    RPNNMSTHRESHOLD = 0.7\n",
    "    DETECTIONMINCONFIDENCE = 0.7\n",
    "    DETECTIONNMSTHRESHOLD = 0.3\n",
    "    TRAINROISPER_IMAGE = 200\n",
    "    RPNTRAINANCHORSPERIMAGE = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = MaskConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskDataset()\n",
    "dataset.load_dataset(DATASET_DIR, 'train')\n",
    "dataset.prepare()\n",
    "\n",
    "print('[INFO] Image Count: {}'.format(len(dataset.image_ids)))\n",
    "print('[INFO] Class Count: {}'.format(dataset.num_classes))\n",
    "for i, info in enumerate(dataset.class_info):\n",
    "    print('{:3}. {:50}'.format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    print('[INFO] Image ID: {}'.format(image_id))\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_id =  np.random.choice(dataset.image_ids, 1)[0]\n",
    "image = dataset.load_image(image_id)\n",
    "mask, class_ids = dataset.load_mask(image_id)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "\n",
    "print('[INFO] Image Shape: {} \\tClass ID : {}'.format(mask.shape, class_ids))\n",
    "print('[INFO] Image ID: {} \\tDataset Reference: {}'.format(image_id, dataset.image_reference(image_id)))\n",
    "log('[INFO] Image', image)\n",
    "log('[INFO] Mask', mask)\n",
    "log('[INFO] Class IDs', class_ids)\n",
    "log('[INFO] BBOX', bbox)\n",
    "\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_id = np.random.choice(dataset.image_ids, 1)[0]\n",
    "image = dataset.load_image(image_id)\n",
    "mask, class_ids = dataset.load_mask(image_id)\n",
    "original_shape = image.shape\n",
    "\n",
    "image, window, scale, padding, _ = utils.resize_image(\n",
    "    image, \n",
    "    min_dim=config.IMAGE_MIN_DIM, \n",
    "    max_dim=config.IMAGE_MAX_DIM,\n",
    "    mode=config.IMAGE_RESIZE_MODE)\n",
    "mask = utils.resize_mask(mask, scale, padding)\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "print('[INFO] Image ID: {} \\tDataset Reference: {}'.format(image_id, dataset.image_reference(image_id)))\n",
    "print('[INFO] Original Shape: ', original_shape)\n",
    "log('[INFO] Image', image)\n",
    "log('[INFO] Mask', mask)\n",
    "log('[INFO] Class IDs', class_ids)\n",
    "log('[INFO] BBOX', bbox)\n",
    "\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_id = np.random.choice(dataset.image_ids, 1)[0]\n",
    "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "    dataset, config, image_id, use_mini_mask=False)\n",
    "\n",
    "log('[INFO] Image', image)\n",
    "log('[INFO] Class IDs', class_ids)\n",
    "log('[INFO] BBOX', bbox)\n",
    "log('[INFO] Mask', mask)\n",
    "log('[INFO] Image Metas', image_meta)\n",
    "\n",
    "display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(\n",
    "    dataset,\n",
    "    config,\n",
    "    image_id,\n",
    "    augmentation=iaa.Affine(rotate=(-35, 35)),\n",
    "    use_mini_mask=False\n",
    "  )\n",
    "\n",
    "log('[INFO] Mask', mask)\n",
    "display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = utils.expand_mask(bbox, mask, image.shape)\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone_shapes = modellib.compute_backbone_shapes(config, config.IMAGE_SHAPE)\n",
    "anchors = utils.generate_pyramid_anchors(\n",
    "    config.RPN_ANCHOR_SCALES, \n",
    "    config.RPN_ANCHOR_RATIOS,\n",
    "    backbone_shapes,\n",
    "    config.BACKBONE_STRIDES, \n",
    "    config.RPN_ANCHOR_STRIDE\n",
    "  )\n",
    "\n",
    "num_levels = len(backbone_shapes)\n",
    "anchors_per_cell = len(config.RPN_ANCHOR_RATIOS)\n",
    "print('[INFO] Anchors Count: ', anchors.shape[0])\n",
    "print('[INFO] Scales: ', config.RPN_ANCHOR_SCALES)\n",
    "print('[INFO] Ratios: ', config.RPN_ANCHOR_RATIOS)\n",
    "print('[INFO] Anchors per Cell: ', anchors_per_cell)\n",
    "print('[INFO] Levels: ', num_levels)\n",
    "\n",
    "anchors_per_level = []\n",
    "for l in range(num_levels):\n",
    "    num_cells = backbone_shapes[l][0] * backbone_shapes[l][1]\n",
    "    anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2)\n",
    "    print('Anchors at Level {}: {}'.format(l, anchors_per_level[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_id = np.random.choice(dataset.image_ids, 1)[0]\n",
    "image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id)\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "ax.imshow(image)\n",
    "levels = len(backbone_shapes)\n",
    "\n",
    "for level in range(levels):\n",
    "    colors = visualize.random_colors(levels)\n",
    "    level_start = sum(anchors_per_level[:level])\n",
    "    level_anchors = anchors[level_start:level_start+anchors_per_level[level]]\n",
    "    print('Level {}. Anchors: {:6}  Feature map Shape: {}'.format(level, level_anchors.shape[0], \n",
    "                                                                  backbone_shapes[level]))\n",
    "    center_cell = backbone_shapes[level] // 2\n",
    "    center_cell_index = (center_cell[0] * backbone_shapes[level][1] + center_cell[1])\n",
    "    level_center = center_cell_index * anchors_per_cell \n",
    "    center_anchor = anchors_per_cell * (\n",
    "        (center_cell[0] * backbone_shapes[level][1] / config.RPN_ANCHOR_STRIDE**2) \\\n",
    "        + center_cell[1] / config.RPN_ANCHOR_STRIDE)\n",
    "    level_center = int(center_anchor)\n",
    "\n",
    "    for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]):\n",
    "        y1, x1, y2, x2 = rect\n",
    "        p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor='none',\n",
    "                              edgecolor=(i+1)*np.array(colors[level]) / anchors_per_cell)\n",
    "        ax.add_patch(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rois = 2000\n",
    "g = modellib.data_generator(\n",
    "    dataset, config, shuffle=True, random_rois=random_rois, \n",
    "    batch_size=4,\n",
    "    detection_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if random_rois:\n",
    "    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks, rpn_rois, rois], \\\n",
    "    [mrcnn_class_ids, mrcnn_bbox, mrcnn_mask] = next(g)\n",
    "    \n",
    "    log('[INFO] rois', rois)\n",
    "    log('[INFO] mrcnn_class_ids', mrcnn_class_ids)\n",
    "    log('[INFO] mrcnn_bbox', mrcnn_bbox)\n",
    "    log('[INFO] mrcnn_mask', mrcnn_mask)\n",
    "else:\n",
    "    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_boxes, gt_masks], _ = next(g)\n",
    "    \n",
    "log('[INFO] gt_class_ids', gt_class_ids)\n",
    "log('[INFO] gt_boxes', gt_boxes)\n",
    "log('[INFO] gt_masks', gt_masks)\n",
    "log('[INFO] rpn_match', rpn_match, )\n",
    "log('[INFO] rpn_bbox', rpn_bbox)\n",
    "image_id = modellib.parse_image_meta(image_meta)['image_id'][0]\n",
    "print('[INFO] Image ID: {} \\tDataset Reference: {}'.format(image_id, dataset.image_reference(image_id)))\n",
    "\n",
    "mrcnn_class_ids = mrcnn_class_ids[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "sample_image = modellib.unmold_image(normalized_images[b], config)\n",
    "\n",
    "indices = np.where(rpn_match[b] == 1)[0]\n",
    "refined_anchors = utils.apply_box_deltas(anchors[indices], rpn_bbox[b, :len(indices)] * config.RPN_BBOX_STD_DEV)\n",
    "log('anchors', anchors)\n",
    "log('refined_anchors', refined_anchors)\n",
    "\n",
    "positive_anchor_ids = np.where(rpn_match[b] == 1)[0]\n",
    "print('Positive anchors: {}'.format(len(positive_anchor_ids)))\n",
    "negative_anchor_ids = np.where(rpn_match[b] == -1)[0]\n",
    "print('Negative anchors: {}'.format(len(negative_anchor_ids)))\n",
    "neutral_anchor_ids = np.where(rpn_match[b] == 0)[0]\n",
    "print('Neutral anchors: {}'.format(len(neutral_anchor_ids)))\n",
    "\n",
    "for c, n in zip(dataset.class_names, np.bincount(mrcnn_class_ids[b].flatten())):\n",
    "    if n:\n",
    "        print('{:23}: {}'.format(c[:20], n))\n",
    "\n",
    "visualize.draw_boxes(sample_image, boxes=anchors[positive_anchor_ids], \n",
    "                     refined_boxes=refined_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize.draw_boxes(sample_image, boxes=anchors[negative_anchor_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize.draw_boxes(sample_image, boxes=anchors[np.random.choice(neutral_anchor_ids, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if random_rois:\n",
    "    bbox_specific = mrcnn_bbox[b, np.arange(mrcnn_bbox.shape[1]), mrcnn_class_ids[b], :]\n",
    "    refined_rois = utils.apply_box_deltas(rois[b].astype(np.float32), bbox_specific[:,:4] * config.BBOX_STD_DEV)\n",
    "    mask_specific = mrcnn_mask[b, np.arange(mrcnn_mask.shape[1]), :, :, mrcnn_class_ids[b]]\n",
    "    visualize.draw_rois(sample_image, rois[b], refined_rois, mask_specific, mrcnn_class_ids[b], dataset.class_names)\n",
    "    \n",
    "    rows = np.ascontiguousarray(rois[b]).view(np.dtype((np.void, rois.dtype.itemsize * rois.shape[-1])))\n",
    "    _, idx = np.unique(rows, return_index=True)\n",
    "    print('Unique ROIs: {} out of {}'.format(len(idx), rois.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if random_rois:\n",
    "    ids = random.sample(range(rois.shape[1]), 8)\n",
    "\n",
    "    images = []\n",
    "    titles = []\n",
    "    for i in ids:\n",
    "        image = visualize.draw_box(sample_image.copy(), rois[b,i,:4].astype(np.int32), [255, 0, 0])\n",
    "        image = visualize.draw_box(image, refined_rois[i].astype(np.int64), [0, 255, 0])\n",
    "        images.append(image)\n",
    "        titles.append('ROI {}'.format(i))\n",
    "        images.append(mask_specific[i] * 255)\n",
    "        titles.append(dataset.class_names[mrcnn_class_ids[b,i]][:20])\n",
    "\n",
    "    display_images(images, titles, cols=4, cmap='Blues', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_rois:\n",
    "    limit = 10\n",
    "    temp_g = modellib.data_generator(\n",
    "        dataset, config, shuffle=True, random_rois=10000, \n",
    "        batch_size=1, detection_targets=True)\n",
    "    total = 0\n",
    "    for i in range(limit):\n",
    "        _, [ids, _, _] = next(temp_g)\n",
    "        positive_rois = np.sum(ids[0] > 0)\n",
    "        total += positive_rois\n",
    "        print('{:5} {:5.2f}'.format(positive_rois, positive_rois/ids.shape[1]))\n",
    "    print('Average percent: {:.2f}'.format(total/(limit*ids.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MaskDataset()\n",
    "dataset_train.load_dataset(DATASET_DIR,'train')\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = MaskDataset()\n",
    "val_coco = dataset_val.load_dataset(DATASET_DIR,'val')\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Loading Mask R-CNN model...')\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_path = model.find_last()\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "except:\n",
    "    model.load_weights('mask_rcnn_coco.h5', \n",
    "                       by_name=True, \n",
    "                       exclude=['mrcnn_class_logits', 'mrcnn_bbox_fc',\n",
    "                                'mrcnn_bbox', 'mrcnn_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flip\n",
    "    iaa.Flipud(0.5), # vertical flip\n",
    "#     iaa.CropAndPad(\n",
    "#         percent=(-0.05, 0.1),\n",
    "#         pad_mode=ia.ALL,\n",
    "#         pad_cval=(0, 255)\n",
    "#     ),\n",
    "#     iaa.Affine(\n",
    "#         scale={'x': (0.8, 1.2), 'y': (0.8, 1.2)}, # scale from 80-120%\n",
    "#         translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to 20 %\n",
    "#         rotate=(-45, 45), # rotate by -45 to 45\n",
    "#         shear=(-8, 8),\n",
    "#         order=[0, 1],\n",
    "#         cval=(0, 255),\n",
    "#         mode=ia.ALL\n",
    "#     )\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Training network')\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=20,\n",
    "            layers='4+',\n",
    "            augmentation=augmentation\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_DIR + '/val.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for x in data['categories']:\n",
    "    d[x['name']] = x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_category = [0]\n",
    "for x in dataset.class_names[1:]:\n",
    "    id_category.append(d[x])\n",
    "id_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_map_id = {}\n",
    "for x in data['images']:\n",
    "    val_images_map_id[x['file_name']] = x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(MaskConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 3  # 1 Background + 61 classes\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    NAME = 'mask-detection'\n",
    "    DETECTIONMINCONFIDENCE = 0.8\n",
    "    RPNNMSTHRESHOLD = 0.6\n",
    "    DETECTIONNMSTHRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig()\n",
    "inference_config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_val = modellib.MaskRCNN(mode='inference', \n",
    "                          config=inference_config,\n",
    "                          model_dir='./')\n",
    "model_path = model_val.find_last()\n",
    "assert model_path != '', 'Provide path to trained weights'\n",
    "print('Loading weights from ', model_path)\n",
    "model_val.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset_val\n",
    "fig = plt.figure(figsize=(15, 30))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    image_id = random.choice(dataset.image_ids)\n",
    "    \n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "    \n",
    "    print(original_image.shape)\n",
    "    plt.subplot(6, 2, 2*i + 1)\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names, ax=fig.axes[-1])\n",
    "    \n",
    "    plt.subplot(6, 2, 2*i + 2)\n",
    "    results = model_val.detect([original_image])\n",
    "    r = results[0]\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], ax=fig.axes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATASET_DIR + 'val_images')\n",
    "_final_object = []\n",
    "\n",
    "for f in tqdm(files, total=len(files)):\n",
    "    try:\n",
    "        images = [cv2.imread(DATASET_DIR + 'val_images/' + f) ]\n",
    "        predictions = model_val.detect(images, verbose=0)\n",
    "\n",
    "        for _idx, r in enumerate(predictions):\n",
    "\n",
    "            image_id = f.split('.')[0]\n",
    "            for _idx, class_id in enumerate(r['class_ids']):\n",
    "                if class_id > 0:\n",
    "                    mask = r['masks'].astype(np.uint8)[:, :, _idx]\n",
    "                    bbox = np.around(r['rois'][_idx], 1)\n",
    "                    bbox = [float(x) for x in bbox]\n",
    "                    _result = {}\n",
    "                    _result['image_id'] = val_images_map_id[f]\n",
    "                    _result['category_id'] = id_category[class_id]\n",
    "                    _result['score'] = float(r['scores'][_idx])\n",
    "                    _mask = maskUtils.encode(np.asfortranarray(mask))\n",
    "                    _mask['counts'] = _mask['counts'].decode('UTF-8')\n",
    "                    _result['segmentation'] = _mask\n",
    "                    _result['bbox'] = [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]]\n",
    "                    _final_object.append(_result)\n",
    "    except:\n",
    "        print('Error with',f)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('data/output.json', 'w')\n",
    "print('Writing JSON...')\n",
    "fp.write(json.dumps(_final_object))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = json.loads(open('data/output.json').read())\n",
    "len(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_ANNOTATION_PATH = DATASET_DIR + 'val.json'\n",
    "ground_truth_annotations = COCO(GROUND_TRUTH_ANNOTATION_PATH)\n",
    "submission_file = json.loads(open('data/output.json').read())\n",
    "results = ground_truth_annotations.loadRes(submission_file)\n",
    "cocoEval = COCOeval(ground_truth_annotations, results, 'bbox')\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASET_DIR + '/test.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_map_id={}\n",
    "for x in data['images']:\n",
    "    test_images_map_id[x['file_name']] = x['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATASET_DIR + 'test_images')\n",
    "_final_object = []\n",
    "for f in tqdm(files,total=len(files)):\n",
    "    try:\n",
    "        images = [cv2.imread(DATASET_DIR + 'test_images/' + f)]\n",
    "        predictions = model_val.detect(images, verbose=0)\n",
    "\n",
    "        for _idx, r in enumerate(predictions):\n",
    "            image_id = f.split('.')[0]\n",
    "            for _idx, class_id in enumerate(r['class_ids']):\n",
    "                if class_id > 0:\n",
    "                    mask = r['masks'].astype(np.uint8)[:, :, _idx]\n",
    "                    bbox = np.around(r['rois'][_idx], 1)\n",
    "                    bbox = [float(x) for x in bbox]\n",
    "                    _result = {}\n",
    "                    _result['image_id'] = test_images_map_id[f]\n",
    "                    _result['category_id'] = id_category[class_id]\n",
    "                    _result['score'] = float(r['scores'][_idx])\n",
    "                    _mask = maskUtils.encode(np.asfortranarray(mask))\n",
    "                    _mask['counts'] = _mask['counts'].decode('UTF-8')\n",
    "                    _result['segmentation'] = _mask\n",
    "                    _result['bbox'] = [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]]\n",
    "                    _final_object.append(_result)\n",
    "\n",
    "\n",
    "    except:\n",
    "        print('Error with',f)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('data/submission.json', 'w')\n",
    "print('Writing JSON...')\n",
    "fp.write(json.dumps(_final_object))\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
